# -*- coding: utf-8 -*-
"""Image_Classification_Belajar_Pengembangan_Machine_Learning.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1kMzMLzE25QnIZbb83DhYHtYVSm4r8doQ

# Submisi Image Classification Belajar Pengembangan Machine Learning
## Nama : Husni Naufal Zuhdi

## Scoring Criterias

Minimum Criteria
1. Dataset yang akan dipakai bebas, namun minimal memiliki 1000 buah gambar(v)
2. Dataset dibagi menjadi 80% train set dan 20% test set(v)
3. Model harus menggunakan model sequential(v)
4. Model harus menggunakan Conv2D Maxpooling Layer(v)
5. Akurasi pada training dan validation set minimal sebesar 80%(v)
6. Menggunakan Callback(v)
7. Membuat plot terhadap akurasi dan loss model(v)
8. Menulis kode untuk menyimpan model ke dalam format TF-Lite(v)

High Score Criteria
1. Dataset yang digunakan berisi lebih dari 2000 gambar(v)
2. Mengimplementasikan Callback(v)
3. Gambar-gambar pada dataset memiliki resolusi yang tidak seragam(x)

4 Star Criteria
1. Semua ketentuan terpenuhi(v)
2. Dataset memiliki minimal 2000 sampel gambar dan minimal 3 kelas(v)
3. Serta akurasi pada training dan validation set minimal 85%(x)

5 Star Criteria
1. Semua ketentuan terpenuhi(v)
2. Dataset memiliki minimal 10000 gambar(v)
3. Resolusi gambar pada dataset tidak seragam(x)
4. Serta akurasi pada training set dan validation set minimal 92%(x)

## Pre Processing
"""

# The process to acces Kaggle API refer to this article
# https://www.kaggle.com/general/74235
# Install kaggle API
! pip install -q kaggle

# Insert my kaggle json key
from google.colab import files
! mkdir ~/.kaggle
! cp kaggle.json ~/.kaggle/
! chmod 600 ~/.kaggle/kaggle.json

# # Download ASL Alphabet Dataset
# # https://www.kaggle.com/grassknoted/asl-alphabet
! kaggle datasets download -d grassknoted/asl-alphabet

# Unzip the dataset
! unzip /content/asl-alphabet.zip

# Import libraries
import os
import pandas as pd
import tensorflow as tf
from keras.preprocessing import image
import matplotlib.pyplot as plt
import matplotlib.image as mpimg
import matplotlib.pyplot as plt
import matplotlib.image as mpimg
from tensorflow.keras.preprocessing.image import ImageDataGenerator

# Gain insight from images dataset
alpha = os.listdir('/content/asl_alphabet_train/asl_alphabet_train')
for letter in alpha:
  print(f'total {letter} \t:', len(os.listdir(f'/content/asl_alphabet_train/asl_alphabet_train/{letter}')))

# Commented out IPython magic to ensure Python compatibility.
# See sample image
# %matplotlib inline
img = image.load_img('/content/asl_alphabet_train/asl_alphabet_train/A/A1.jpg')
imgplot = plt.imshow(img)

# Images Augmentation
train_dir = train_dir = os.path.join('/content/asl_alphabet_train/asl_alphabet_train')
train_datagen = ImageDataGenerator(rescale=1./255,
    rotation_range=20,
    zoom_range=0.2,
    shear_range=0.2,
    fill_mode = 'nearest',
    validation_split=0.2)

# Generate Image Dataset
train_generator = train_datagen.flow_from_directory(
    train_dir,
    target_size=(64, 64),
    batch_size=8,
    class_mode='categorical',
    subset='training')
validation_generator = train_datagen.flow_from_directory(
    train_dir,
    target_size=(64, 64),
    batch_size=16,
    class_mode='categorical',
    subset='validation')

"""## Build Machine Learning Model"""

# # Build the Model
# model = tf.keras.models.Sequential([
#     tf.keras.layers.Conv2D(64, kernel_size=4, strides=1, activation='relu', input_shape=(64, 64, 3)),
#     tf.keras.layers.Conv2D(64, kernel_size=4, strides=2, activation='relu'),
#     tf.keras.layers.Dropout(0.5),
#     tf.keras.layers.Conv2D(128, kernel_size=4, strides=1, activation='relu'),
#     tf.keras.layers.Conv2D(128, kernel_size=4, strides=2, activation='relu'),
#     tf.keras.layers.Dropout(0.5),
#     tf.keras.layers.Conv2D(256, kernel_size=4, strides=1, activation='relu'),
#     tf.keras.layers.Conv2D(256, kernel_size=4, strides=2, activation='relu'),
#     # Flatten the results to feed into a DNN
#     tf.keras.layers.Flatten(), 
#     # 512 neuron hidden layer
#     tf.keras.layers.Dense(256, activation='relu'),
#     tf.keras.layers.Dense(29, activation='softmax')  
# ])
# model.compile(optimizer=tf.optimizers.Adam(),
#               loss='categorical_crossentropy',
#               metrics = ['accuracy'])

# Build the Model
model = tf.keras.models.Sequential([
    # Note the input shape is the desired size of the image 150x150 with 3 bytes color
    tf.keras.layers.Conv2D(64, (3,3), activation='relu', input_shape=(64, 64, 3)),
    tf.keras.layers.MaxPooling2D(2,2),
    tf.keras.layers.Conv2D(32, (3,3), activation='relu'),
    tf.keras.layers.MaxPooling2D(2,2),
    tf.keras.layers.Dropout(0.4),  
    tf.keras.layers.Conv2D(64, (3,3), activation='relu'), 
    tf.keras.layers.MaxPooling2D(2,2),
    tf.keras.layers.Dropout(0.4),  
    # Flatten the results to feed into a DNN
    tf.keras.layers.Flatten(), 
    # 512 neuron hidden layer
    # tf.keras.layers.Dense(512, activation='relu'),
    tf.keras.layers.Dense(64, activation='relu'),
    tf.keras.layers.Dense(29, activation='softmax')  
])
model.compile(optimizer=tf.optimizers.Adam(),
              loss='categorical_crossentropy',
              metrics = ['accuracy'])

# Build Callback Class
class myCallback(tf.keras.callbacks.Callback):
  def on_epoch_end(self, epoch, logs={}):
    if(logs.get('accuracy')>0.93):
      if(logs.get('val_accuracy')>0.93):
        print("\nModel accuracy and Validation accuracy reach >93%!")
        self.model.stop_training = True
callbacks = myCallback()

"""## Train and Test Model"""

# Prepare to use GPU
tf.test.gpu_device_name()

from tensorflow.python.client import device_lib
device_lib.list_local_devices()

# Train Model
history = model.fit(train_generator,
                    validation_data=validation_generator,
                    epochs=50,
                    callbacks=[callbacks],
                    verbose=2)

# See model summary
model.summary()

"""## Evaluate"""

# Plot Accuracy
plt.plot(history.history['accuracy'])
plt.plot(history.history['val_accuracy'])
plt.title('Model Accuracy')
plt.ylabel('accuracy')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='upper left')
plt.show()

# Plot Loss
plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('Model Loss')
plt.ylabel('loss')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='upper left')
plt.show()

"""## Save Model"""

# Convert Model
converter = tf.lite.TFLiteConverter.from_keras_model(model)
tflite_model = converter.convert()

# Save the TFlite Model
with tf.io.gfile.GFile('model.tflite', 'wb') as f:
  f.write(tflite_model)

# See directory to make sure tflite model already created
! ls -l